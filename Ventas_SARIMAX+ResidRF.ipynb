{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f06f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305f14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87906c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18abe8bb-e69c-4b0f-91db-7d24c3f5cc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ventas', 'empleo', 'pib', 'ifb', 'inpc', 'cetes', 'tc', 'cc', 'sofr']\n",
      "       fecha       igae          msr      empleo       inpc  cetes28  easter  \\\n",
      "0 2008-01-01  82.477618  4941.491605  14173391.0  65.350564   7.4160       0   \n",
      "1 2008-02-01  81.216819  4944.303601  14247806.0  65.544834   7.4275       0   \n",
      "2 2008-03-01  80.733071  4908.735873  14253166.0  66.019891   7.4325       1   \n",
      "3 2008-04-01  86.804124  4914.785752  14334667.0  66.170127   7.4420       0   \n",
      "4 2008-05-01  85.475305  4983.741773  14338395.0  66.098635   7.4375       0   \n",
      "\n",
      "      ventas  \n",
      "0  91.639024  \n",
      "1  85.791571  \n",
      "2  86.879309  \n",
      "3  88.726848  \n",
      "4  90.323966  \n",
      "Ultima fecha con datos de ventas: 2024-07-01 00:00:00\n",
      "Iteración 1:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m    102\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mtscv, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 103\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_scaled, y)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;66;03m# Mejor modelo\u001b[39;00m\n\u001b[0;32m    106\u001b[0m best_rf \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\IvannaRodriguez\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Importar librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import openpyxl\n",
    "\n",
    "# Ruta del archivo\n",
    "file_path = 'Datos.xlsx'\n",
    "\n",
    "# Cargar el archivo de Excel\n",
    "data = pd.ExcelFile(file_path)\n",
    "\n",
    "# Inspeccionar los nombres de las hojas disponibles\n",
    "print(data.sheet_names)\n",
    "\n",
    "# Cargar la hoja relevante ('ventas')\n",
    "ventas_data = data.parse('ventas')\n",
    "\n",
    "# Inspeccionar las primeras filas del conjunto de datos\n",
    "print(ventas_data.head())\n",
    "\n",
    "# Convertir la columna 'fecha' a formato datetime para facilitar el manejo de fechas\n",
    "ventas_data['fecha'] = pd.to_datetime(ventas_data['fecha'])\n",
    "\n",
    "# Identificar la última fecha con un dato no nulo en la columna 'ventas'\n",
    "ultima_fecha_ventas = ventas_data.loc[ventas_data['ventas'].notna(), 'fecha'].max()\n",
    "print(f'Ultima fecha con datos de ventas: {ultima_fecha_ventas}')\n",
    "\n",
    "# Filtrar los datos hasta la última fecha con ventas disponibles\n",
    "ventas_hasta_actual = ventas_data[ventas_data['fecha'] <= ultima_fecha_ventas].copy()\n",
    "\n",
    "# Asegurar que las predicciones se extiendan hasta diciembre 2029\n",
    "fecha_fin_prediccion = '2029-12-01'\n",
    "fechas_futuras = pd.date_range(start=ultima_fecha_ventas + pd.Timedelta(days=1), end=fecha_fin_prediccion, freq='MS')\n",
    "\n",
    "# Crear DataFrame de predicción con las fechas futuras\n",
    "datos_para_predecir = pd.DataFrame({'fecha': fechas_futuras})\n",
    "\n",
    "# Agregar columnas explicativas vacías para las fechas futuras\n",
    "datos_para_predecir = datos_para_predecir.merge(ventas_data.drop(columns=['ventas']), on='fecha', how='left')\n",
    "datos_para_predecir['ventas'] = np.nan\n",
    "\n",
    "# Inicializar residuales y error objetivo\n",
    "error_objetivo =  1.95\n",
    "error_actual = float('inf')\n",
    "iteracion = 0\n",
    "\n",
    "# Ciclo de reentrenamiento hasta minimizar el error\n",
    "while error_actual > error_objetivo:\n",
    "    iteracion += 1\n",
    "    print(f\"Iteración {iteracion}:\")\n",
    "\n",
    "    # Ajustar SARIMAX automáticamente según ACF y PACF\n",
    "    def ajustar_sarimax(datos, orden):\n",
    "        modelo = SARIMAX(datos, order=orden, seasonal_order=(1, 0, 1, 12))\n",
    "        resultado = modelo.fit(disp=False)\n",
    "        return resultado\n",
    "\n",
    "    # Calcular ACF y PACF\n",
    "    ventas_series = ventas_hasta_actual['ventas']\n",
    "    orden_sarimax = (1, 1, 1)  # Basado en ACF y PACF\n",
    "\n",
    "    # Ajustar modelo SARIMAX\n",
    "    modelo_sarimax = ajustar_sarimax(ventas_series, orden_sarimax)\n",
    "    pronostico_sarimax = modelo_sarimax.forecast(steps=len(datos_para_predecir))\n",
    "    datos_para_predecir['pronostico_sarimax'] = pronostico_sarimax.values\n",
    "\n",
    "    # Preparar los datos para el modelo Random Forest\n",
    "    variables_explicativas = [\"igae\", \"msr\", \"empleo\", \"inpc\", \"cetes28\", \"easter\"]\n",
    "    X = ventas_hasta_actual[variables_explicativas].copy()\n",
    "    y = ventas_hasta_actual[\"ventas\"].copy()\n",
    "\n",
    "    # Crear características adicionales como rezagos\n",
    "    for lag in range(1, 4):\n",
    "        X[f'ventas_lag_{lag}'] = ventas_hasta_actual['ventas'].shift(lag)\n",
    "        datos_para_predecir[f'ventas_lag_{lag}'] = ventas_hasta_actual['ventas'].shift(lag).iloc[-len(datos_para_predecir):].values\n",
    "\n",
    "    # Limpiar los valores NaN generados por los rezagos en los datos históricos\n",
    "    X = X.dropna()\n",
    "    y = y.iloc[X.index]\n",
    "\n",
    "    # Escalar las variables explicativas\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Dividir los datos usando TimeSeriesSplit para respetar la secuencia temporal\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 300, 500],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=tscv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_scaled, y)\n",
    "\n",
    "    # Mejor modelo\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    print(f\"Mejores hiperparámetros: {grid_search.best_params_}\")\n",
    "\n",
    "    # Predecir para las fechas futuras\n",
    "    required_columns = variables_explicativas + [f'ventas_lag_{lag}' for lag in range(1, 4)]\n",
    "    datos_para_predecir = datos_para_predecir.dropna(subset=required_columns)\n",
    "    if not datos_para_predecir.empty:\n",
    "        X_futuro = datos_para_predecir[required_columns]\n",
    "        X_futuro_scaled = scaler.transform(X_futuro)\n",
    "        predicciones_rf_futuro = best_rf.predict(X_futuro_scaled)\n",
    "\n",
    "        # Integrar los pronósticos de ambos modelos\n",
    "        datos_para_predecir['pronostico_rf'] = predicciones_rf_futuro\n",
    "\n",
    "        # Combinar pronósticos (promedio de ambos modelos)\n",
    "        datos_para_predecir['pronostico_combinado'] = (datos_para_predecir['pronostico_sarimax'] + datos_para_predecir['pronostico_rf']) / 2\n",
    "\n",
    "        # Calcular residuales y error\n",
    "        residuales = y - best_rf.predict(X_scaled)\n",
    "        mae = mean_absolute_error(y, best_rf.predict(X_scaled)).round(4)\n",
    "        error_actual = mae.round(2)\n",
    "        print(f\"Error MAE actual: {mae}\")\n",
    "\n",
    "        # Actualizar datos históricos con residuales ajustados\n",
    "        ventas_hasta_actual['ventas'] += residuales.mean()\n",
    "    else:\n",
    "        print(\"No hay suficientes datos futuros para realizar predicciones.\")\n",
    "        break\n",
    "\n",
    "# Exportar el pronóstico combinado a Excel\n",
    "output_file = 'pronostico_ventas_reentrenado.xlsx'\n",
    "datos_para_predecir.to_excel(output_file, index=False)\n",
    "print(f\"Pronóstico exportado a {output_file}\")\n",
    "\n",
    "# Calcular la importancia de las variables explicativas desde el modelo Random Forest ajustado\n",
    "importancia_variables = best_rf.feature_importances_\n",
    "importancia_porcentaje = (importancia_variables / importancia_variables.sum()) * 100\n",
    "\n",
    "# Crear un DataFrame para presentar los resultados\n",
    "importancia_df = pd.DataFrame({\n",
    "    'Variable': X.columns,  # Usar los nombres de las columnas originales del conjunto X\n",
    "    'Importancia (%)': importancia_porcentaje\n",
    "}).sort_values(by='Importancia (%)', ascending=False)\n",
    "\n",
    "# Imprimir la importancia de las variables\n",
    "print(\"Porcentaje de rendimiento de cada variable explicativa:\")\n",
    "print(importancia_df)\n",
    "\n",
    "# Crear un gráfico de pastel para visualizar la importancia de las variables\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(importancia_df['Importancia (%)'], \n",
    "        labels=importancia_df['Variable'], \n",
    "        autopct='%1.1f%%', \n",
    "        startangle=140)\n",
    "plt.title('Importancia de las Variables (%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9697f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d6723-a5c5-4811-942f-69f6d5f79691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
